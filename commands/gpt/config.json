{
  "defaultTemperature": 0.5,
  "defaultHistoryMode": "enabled",
  "globalInputLimit": 5000,
  "outputLimit": {
    "default": 50,
    "maximum": 100
  },
  "lengthLimitExceededMessage": {
    "history": "Maximum input + history length exceeded for this model! Shorten your query, or clear your history with \"$gpt history:clear\" instead.",
    "regular": "Maximum query length exceeded for this model! Shorten your query instead."
  },
  "userTokenLimits": {
    "regular": {
      "hourly": 700,
      "daily": 1600
    },
    "subscriber": {
      "hourly": 7000,
      "daily": 16000
    }
  },
  "models": {
    "base": {
      "url": "gpt-5",
      "type": "openai",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 5.50,
      "usesCompletionTokens": true
    },
    "mini": {
      "url": "gpt-5-mini",
      "type": "openai",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 1.12,
      "usesCompletionTokens": true
    },
    "nano": {
      "url": "gpt-5-nano",
      "type": "openai",
      "default": true,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 0.22,
      "usesCompletionTokens": true
    },
    "mini-old": {
      "url": "gpt-4.1-mini",
      "type": "openai",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 0.42
    },
    "base-old": {
      "url": "gpt-4.1",
      "type": "openai",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 1.84
    },
    "nano-old": {
      "url": "gpt-4.1-nano",
      "type": "openai",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 150,
        "maximum": 500
      },
      "pricePerMtoken": 0.12
    },
    "search": {
      "url": "gpt-4o-mini-search-preview",
      "type": "openai",
      "default": false,
      "inputLimit": 1000,
      "outputLimit": {
        "default": 250,
        "maximum": 500
      },
      "search": true,
      "pricePerMtoken": 0.12,
      "flatCost": 3000
    },
    "mixtral": {
      "url": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "type": "deepinfra",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 500,
        "maximum": 1000
      },
      "pricePerMtoken": 0.65
    },
    "gemma": {
      "url": "google/gemma-1.1-7b-it",
      "type": "deepinfra",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 500,
        "maximum": 1000
      },
      "pricePerMtoken": 0.07
    },
    "mistral": {
      "url": "mistralai/Mistral-7B-Instruct-v0.3",
      "type": "deepinfra",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 500,
        "maximum": 1000
      },
      "pricePerMtoken": 0.07
    },
    "llama": {
      "url": "meta-llama/Meta-Llama-3-8B-Instruct",
      "type": "deepinfra",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 500,
        "maximum": 1000
      },
      "pricePerMtoken": 0.08
    },
    "maverick": {
      "url": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "type": "deepinfra",
      "default": false,
      "inputLimit": 1000,
      "outputLimit": {
        "default": 500,
        "maximum": 1000
      },
      "pricePerMtoken": 0.25
    }
  }
}
