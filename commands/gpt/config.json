{
  "defaultTemperature": 0.5,
  "defaultHistoryMode": "enabled",
  "globalInputLimit": 5000,
  "outputLimit": {
    "default": 50,
    "maximum": 100
  },
  "lengthLimitExceededMessage": {
    "history": "Maximum history length exceeded for this model! Shorten your query, or clear your history with \"$gpt history:clear\" instead.",
    "regular": "Maximum query length exceeded for this model! Shorten your query instead."
  },
  "userTokenLimits": {
    "regular": {
      "hourly": 700,
      "daily": 1600
    },
    "subscriber": {
      "hourly": 7000,
      "daily": 16000
    }
  },
  "models": {
    "base-babbage": {
      "url": "babbage-002",
      "type": "string",
      "default": false,
      "inputLimit": 2500,
      "outputLimit": {
        "default": 100,
        "maximum": 500
      },
      "usageDivisor": 2.5
    },
    "base-davinci": {
      "url": "davinci-002",
      "type": "string",
      "default": false,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 100,
        "maximum": 500
      },
      "usageDivisor": 0.5
    },
    "turbo": {
      "url": "gpt-3.5-turbo-0125",
      "type": "messages",
      "default": true,
      "inputLimit": 1500,
      "outputLimit": {
        "default": 100,
        "maximum": 500
      },
      "usageDivisor": 1
    },
    "nexra-4": {
      "url": "gpt-4-32k",
      "type": "nexra",
      "experimental": true,
      "default": false,
      "inputLimit": 5000,
      "outputLimit": {
        "default": 5000,
        "maximum": 5000
      },
      "usageDivisor": 10
    },
    "4": {
      "url": "gpt-4-1106-preview",
      "type": "messages",
      "default": false,
      "inputLimit": 500,
      "outputLimit": {
        "default": 100,
        "maximum": 250
      },
      "usageDivisor": 0.2
    }
  }
}
